{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c23b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53653ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('--disable-infobars')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--remote-debugging-port=9222')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ede13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get beer data from the soup\n",
    "\n",
    "def get_beer(soup, n):\n",
    "    try: \n",
    "        return soup.select('.row')[1].select('.table')[0].select('tr')[n].select('td')[0].text\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def get_beer_link(soup, n):\n",
    "    try:\n",
    "        return soup.select('.row')[1].select('.table')[0].select('tr')[n].select('td')[0].select('a')[0]['href']\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def get_user_rating(soup, n):\n",
    "    try:\n",
    "        return soup.select('.row')[1].select('.table')[0].select('tr')[n].select('td')[1].text\n",
    "    except:\n",
    "        return 'NaN'\n",
    "\n",
    "def get_avg_rating(soup, n):\n",
    "    try:\n",
    "        return soup.select('.row')[1].select('.table')[0].select('tr')[n].select('td')[3].text\n",
    "    except:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8368d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scraping user ratings\n",
    "\n",
    "# a number of user ids for more active users (i.e. those with more ratings and reviews) were scraped from ratebeer.com and saved as a .txt file\n",
    "with open('./raw data/users.txt', 'r') as file:\n",
    "    diff_users = file.read().replace('\\n','')\n",
    "\n",
    "ids = []\n",
    "col = ['beer', 'link', 'user_rating', 'avg_rating', 'id']\n",
    "d = {i: [] for i in col}\n",
    "\n",
    "for i in tqdm(range(len(diff_users))):\n",
    "    \n",
    "    user_id = diff_users[i]\n",
    "    # to avoid duplicates\n",
    "    if user_id in ids:\n",
    "        print(f'Already have data on {user_id}.') \n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        print(f'Scraping beer ratings for {user_id}')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.implicitly_wait(2)  \n",
    "        driver.get(\"https://www.ratebeer.com\"+str(user_id)+\"country/39/5/1/\")\n",
    "        time.sleep(5)\n",
    "        soup = bs(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        try:\n",
    "            beers = soup.select('.row')[1].select('.table')[0].select('tr')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # ignoring users with < 50 ratings; 101 is the limit per page so this scenario is a user with 1 page of beer ratings to scrape\n",
    "        if len(beers) > 50 and len(beers) < 101:\n",
    "            print(f'{user_id} has rated between 50 and 100 Canadian beers.')\n",
    "            for j in tqdm(range(1, len(beers))):\n",
    "                d['beer'].append(get_beer(soup, j))\n",
    "                d['link'].append(get_beer_link(soup, j))\n",
    "                d['user_rating'].append(get_user_rating(soup, j))\n",
    "                d['avg_rating'].append(get_avg_rating(soup, j))\n",
    "                d['id'].append(user_id)  \n",
    "            ids.append(user_id)\n",
    "            print(f'{user_id} done.')\n",
    "\n",
    "        # in this scenario a user has more than 100 ratings (several pages) to scrape\n",
    "        elif len(beers) >= 101:\n",
    "            print(f'{user_id} has rated over 100 Canadian beers.')\n",
    "            driver.quit()\n",
    "            page = 1\n",
    "            pages = True\n",
    "\n",
    "            # start a new loop to scrape data from multiple pages\n",
    "            while pages:\n",
    "                driver = webdriver.Chrome(options=options)\n",
    "                driver.implicitly_wait(2)  \n",
    "                driver.get(\"https://www.ratebeer.com\"+str(user_id)+\"country/39/5/\"+str(page)+\"/\")\n",
    "                print(f'Scraping data from page {str(page)} for {user_id}')\n",
    "                time.sleep(5)\n",
    "                soup = bs(driver.page_source, \"html.parser\")\n",
    "                if get_beer_link(soup, 1) in d['link']:\n",
    "                    print(f'{user_id} done.')\n",
    "                    ids.append(user_id)\n",
    "                    break\n",
    "\n",
    "                # 2000 beer ratings per user limit\n",
    "                elif page >= 21:\n",
    "                    print(f'{user_id} has rated a lot of Canadian beers; stopped at 2000.')\n",
    "                    ids.append(user_id)\n",
    "                    break\n",
    "\n",
    "                # as long as there are 100 beer ratings on the page, scrape all and move on to the next page; \n",
    "                # if there are < 100 ratings, scrape all and exit the loop\n",
    "                else:\n",
    "                    try:\n",
    "                        beers = soup.select('.row')[1].select('.table')[0].select('tr')\n",
    "                        for k in tqdm(range(1, len(beers))):\n",
    "                            d['beer'].append(get_beer(soup, k))\n",
    "                            d['link'].append(get_beer_link(soup, k))\n",
    "                            d['user_rating'].append(get_user_rating(soup, k))\n",
    "                            d['avg_rating'].append(get_avg_rating(soup, k))\n",
    "                            d['id'].append(user_id)\n",
    "                        print(f'{len(beers)-1} beers on this page.')\n",
    "                        driver.quit()\n",
    "                        page += 1\n",
    "                        if len(beers) != 101:\n",
    "                            pages = False\n",
    "                            ids.append(user_id)\n",
    "                            print(f'{user_id} done.')\n",
    "                            break\n",
    "                    except:\n",
    "                        break\n",
    "            \n",
    "        else:\n",
    "            print(f'{user_id} has rated fewer than 50 Canadian beers so will be skipped.')\n",
    "        driver.quit()\n",
    "        \n",
    "        df = pd.DataFrame(data=d, columns = col)\n",
    "        df.to_csv('beer_ratings.csv', index=False)   \n",
    "        print(f'Ratings of {user_id} saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
